{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import csv\nimport re\nimport math\nfrom collections import Counter\nimport random \n\nwith open('rt_reviews.csv', 'r', newline='', encoding='cp1252') as csvfile:\n    reader = csv.DictReader(csvfile)\n    merged_data = []\n    for row in reader:\n        review = row['Review'].lower()\n        row['Review'] = review\n        merged_data.append(row)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Divide the dataset into train, development and test sets\nrandom.shuffle(merged_data)\ntrain_data = merged_data[:int(0.8*len(merged_data))]\ndev_data = merged_data[int(0.8*len(merged_data)):int(0.9*len(merged_data))]\ntest_data = merged_data[int(0.9*len(merged_data)):]\n\n\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Build a vocabulary as a list\nword_freq = {}\nfor review in train_data:\n    words = review['Review'].split()\n    for word in words:\n        if word in word_freq:\n            word_freq[word] += 1\n        else:\n            word_freq[word] = 1\n\nvocabulary = [word for word in word_freq if word_freq[word] >= 5]\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Create a reverse index\nreverse_index = {}\nfor i, word in enumerate(vocabulary):\n    reverse_index[word] = i",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Part C\n# Count the number of documents containing 'the'\ndoc_containing_the = 0\nfor review in train_data:\n    if 'the' in review['Review']:\n        doc_containing_the += 1\n\n# Calculate the probability of occurrence\nP_the = doc_containing_the / len(train_data)\n\nprint(f\"Probability of occurrence of 'the': {P_the:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": "Probability of occurrence of 'the': 0.7131\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Count the number of positive reviews containing 'the'\npos_doc_containing_the = 0\nfor review in train_data:\n    if review['Freshness'] == 'fresh' and 'the' in review['Review']:\n        pos_doc_containing_the += 1\n\n# Calculate the number of positive reviews\nnum_pos_docs = sum([1 for review in train_data if review['Freshness'] == 'fresh'])\n\n# Calculate the conditional probability\nif num_pos_docs != 0:\n    P_the_given_pos = pos_doc_containing_the / num_pos_docs\nelse:\n    P_the_given_pos = 0\n\nprint(f\"Conditional probability of 'the' given Positive: {P_the_given_pos:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "text": "Conditional probability of 'the' given Positive: 0.7068\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}