{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import csv\nimport re\nimport math\nfrom collections import Counter\nimport random \n\nwith open('rt_reviews.csv', 'r', newline='', encoding='cp1252') as csvfile:\n    reader = csv.DictReader(csvfile)\n    merged_data = []\n    for row in reader:\n        review = row['Review'].lower()\n        row['Review'] = review\n        merged_data.append(row)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# creating the function to load the dataset.\ndef LoadDataset(filename):\n    dataset = []\n    with open(filename, 'r') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            dataset.append(row)\n    return dataset",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def reviews_load(filename):\n    reviews = []\n    with open(filename, 'r') as file:\n        reader = csv.DictReader(file)\n        for row in reader:\n            reviews.append(row)\n    return reviews",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# then split the dataset into train, dev, and test sets\ndef split_train_dev_eval(dataset, split_ratio):\n    train_size = int(len(dataset) * split_ratio) # split the train according to input ratio\n    train_dataset = []\n    devandeval = dataset[:]\n    while len(train_dataset) < train_size:\n        index = random.randrange(len(devandeval))\n        train_dataset.append(devandeval.pop(index))\n    return [train_dataset, devandeval, devandeval] #return list contains the three parts.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# function that calculates the word occurence in all reviews\ndef word_occurrences(dataset, vocabulary):\n    WordOccurrences = {}\n    for word in vocabulary:\n        WordOccurrences[word] = 0\n        for document in dataset:\n            if word in document[0].split():\n                WordOccurrences[word] += 1\n    return WordOccurrences",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}